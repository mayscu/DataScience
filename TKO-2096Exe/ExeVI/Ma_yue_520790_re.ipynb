{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-signal data exercise\n",
    "\n",
    "In this exercise you take on the role of a senior data analyst correcting mistakes made by a junior analyst. Your consulting company has received the MysteryData data set, and your goal is to build a classifier out of it, and evaluate how well the classifer works. You assigned the job to junior trainee Tux the Linux Penguin (who works for food).\n",
    "\n",
    "Tux is very excited to work on the data and has produced very promising results. What Tux does not yet know is that MysteryData is actually just random non-signal data where the features x and the class label y are independent of each other - it is not possible to learn anything meaningful from this data. Tux has never taken any of the UTU data analytics courses and has not noticed this. You should help Tux to correct the analyses, so you do not end up reporting incorrect results to your customers.\n",
    "\n",
    "You will write your answers inside this notebook. If all your answers are correct, your explanations thorough, and you solve the bonus questions, you will get a bonus point. Use written text, code, printouts or visualizations in you answers as needed. Return both this notebook filled (rename it lastname_firstname_studentid.ipynb), as well as a pdf export of the same notebook (same naming, but .pdf instead).\n",
    "\n",
    "The analysed problem is a binary classification task. We will follow the convention of using +1 to represent the positive class, and -1 the negative. In all but one task we will use area under ROC curve (AUC) to evaluate how well the classifier predicts. For binary classification tasks AUC and c-index are equivalent, 0.5 means random performance and 1.0 perfect predictions. The \"true\" AUC you would expect to see on a large enough sample of independent test data for any classifier trained on non-signal data is 0.5.\n",
    "\n",
    "Note that amount of samples, features, and class distribution for MysteryData can differ in different parts of the exercise (these are always written in comments above the code generating the data). Also, in one case there will be a data set on which it is possible to learn better than random classifier.\n",
    "\n",
    "Some notes on the codes:\n",
    "- we use predict_proba() instead of predict() when using AUC, because the predicted class probabilities are needed for computing AUC properly (predict() returns only +1/-1 values)\n",
    "- random seeds are fixed to guarantee that re-running the codes gives same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "#The data, trust me, you can't learn anything useful from this\n",
    "def load_mystery_data(samples, features, positives, random_seed):\n",
    "    #samples: sample size\n",
    "    #features: number of features\n",
    "    #positives: number of positive examples, positives <= samples\n",
    "    #random_seed: initializes the random generator\n",
    "    assert positives <= samples\n",
    "    rand_state = np.random.RandomState(random_seed)\n",
    "    #values in X are from normal distribution, with zero mean, unit variance, zero covariance\n",
    "    X = rand_state.randn(samples, features)\n",
    "    #y is a randomly shuffled vector of +1 and -1 values\n",
    "    y = np.hstack((np.ones(positives), -1.*np.ones(samples-positives)))\n",
    "    y = rand_state.permutation(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: some elementary mistakes\n",
    "\n",
    "## Lesson 1.1: never trust your ----- set performance\n",
    "\n",
    "The first analysis done by Tux contains an obvious elementary mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got area under ROC curve 0.885600\n",
      "Tux: \"I got very high AUC, problem solved!!\"\n"
     ]
    }
   ],
   "source": [
    "#100 samples, 100 features, 50 belong to positive class\n",
    "X, y = load_mystery_data(100, 100, 50, 2)\n",
    "\n",
    "#I am going to try knn on my data!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "learner = KNeighborsClassifier(n_neighbors=2)\n",
    "learner.fit(X, y)\n",
    "#get the estimated probability of belonging to class 1\n",
    "p = learner.predict_proba(X)[:,1]\n",
    "auc = roc_auc_score(y, p)\n",
    "print(\"I got area under ROC curve %f\" % auc)\n",
    "print('Tux: \"I got very high AUC, problem solved!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1\n",
    "Why can't you trust the AUC result of Tux?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your answer to question 1.1 here\n",
    "Most importantly, he uses training data to test the model, this makes the results lose credentiality. The model can be really over-optimistic and fail to generalize on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1.2: trivial baselines\n",
    "\n",
    "The second analysis done by Tux is done a bit better, but analysis of results contains another elementary mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.900000\n",
      "Tux: \"I got 90% classification accuracy, problem solved!!\"\"\n"
     ]
    }
   ],
   "source": [
    "#1000 samples, 100 features, 100 belong to positive class\n",
    "X, y = load_mystery_data(1000, 100, 100, 1)\n",
    "\n",
    "#I am going to try knn on my data!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Instead of AUC I will use classification accuracy!\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Now I use a separate test set!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, stratify=y, random_state=1)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "p_test = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, p_test)\n",
    "print(\"Classification accuracy: %f\" %accuracy)\n",
    "print('Tux: \"I got 90% classification accuracy, problem solved!!\"\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2\n",
    "1. Does the high classification accuracy really mean that this is a good predictor?\n",
    "2. Look at the test set predictions in p_test, what has this classifier actually learned?\n",
    "3. What would the results look like if you used AUC instead of classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your answer to question 1.2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. This doesn't mean that a good predictor really, for there is only one trial of testing. The result can to some extent influenced by randomness. Moreover, just accuracy rate can not evaluates the generalizing ability of a predictor. This rate is influenced by the distribution of labels in original data. The accuracy will be high even it just predict one kind of result sometimes.\n",
    "\n",
    "2. The results are all `-1`, which means the predictor just produces one kind of predicted value. This predictor can not be called a \"good\" predictor, it did not learn any thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, p_test)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The AUC is 0.5. This means it just guesses randomly and doesn't have any value in term of predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: introduction to permutation tests\n",
    "\n",
    "Next, we are using permutation tests to estimate, how likely we are to see AUC values as high as observed, if y is independent of x (non-signal data).\n",
    "\n",
    "The test is implemented as follows:\n",
    "- let AUC_original be the AUC obtained in the original analysis\n",
    "- For 1000 (or preferably more if you have enough CPU time to use) repetitions, shuffle the labels in y, then run the analysis again and compute the AUC value. Store all 1000 AUC values in a list.\n",
    "- Visualization: visualize the permutation distribution by plotting a histogram of the 1000 AUC values. Does AUC_original look like an outlier, or do you often get as good or better results with permuted class labels?\n",
    "- p-value: relative fraction of runs, where obtained AUC $\\geq$ AUC_original\n",
    "- example: AUC with original class labeling is 0.6. In 70 runs out of 1000, we obtain as high as or larger AUC. p-value is then $\\frac{70}{1000} = 0.07$ \n",
    "- result is considered statistically significant, if $p<\\alpha$, where $\\alpha$ a pre-specified significance level (often $\\alpha=0.05$ or $\\alpha=0.01$). Statistical significance does not mean that the results are good, only that the classifier has likely learned something from the data. In the following experiments, use $\\alpha=0.05$.\n",
    "\n",
    "## Lesson 2.1: sample size\n",
    "\n",
    "Tux is now analyzing a small data set with 5-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.700000\n",
      "Tux: \"I did proper cross-validation and got better than random results. My classifier learned something!!\"\n"
     ]
    }
   ],
   "source": [
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "auc = np.mean(cv_aucs)\n",
    "print(\"AUC: %f\" %auc)\n",
    "print('Tux: \"I did proper cross-validation and got better than random results. My classifier learned something!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "Implement a permutation test for the above analysis, are these results statistically significant with $\\alpha=0.05$? Provide both visualization of the permutation distribution, as well as the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly capsulate previous pipeline into a function\n",
    "def five_fold_cv(X,y):\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X, y):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    auc = np.mean(cv_aucs)\n",
    "    return auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement permutation test\n",
    "original_auc=auc #define the previous auc as \"original\" auc\n",
    "permutation_auc=[]\n",
    "\n",
    "for i in range(0,1000):\n",
    "    rand_state = np.random.RandomState(i)#create a fixed random seed for each loop\n",
    "    #=================#\n",
    "    #shuffle labels\n",
    "    y_shuffled=rand_state.permutation(y)\n",
    "    #=================#\n",
    "    permutation_auc.append(five_fold_cv(X,y_shuffled))#run the analysis and compute the AUC value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.105>0.05,the result is not significant\n"
     ]
    }
   ],
   "source": [
    "#calculate the p-value of permutation test\n",
    "p_value=float(len(np.where(permutation_auc>=original_auc)[0])/1000.0)\n",
    "alpha=0.05\n",
    "if p_value < alpha:\n",
    "    print(\"{}<{},the result is significant\".format(str(p_value),str(alpha)))\n",
    "else:\n",
    "    print(\"{}>{},the result is not significant\".format(str(p_value),str(alpha)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1a1834ebd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "permutation_auc=np.array(permutation_auc)\n",
    "plt.hist(permutation_auc,rwidth=0.95,alpha=0.4)\n",
    "plt.vlines(original_auc,0,200,label=str(original_auc),color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The red line in the figure is that the original AUC, which is 0.7. So the right parts to the vertical line represents the 10.5% of all repetitions, means p-value is `0.105`.\n",
    "So that these results are not statistically significant with α=0.05. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2.2: sample size again\n",
    "\n",
    "Let's give poor Tux a better data set that actually has clear difference between the classes and see how things work out. (on this data it is possible to obtain true AUC larger than 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_new_mystery_data(samples, features, positives, random_seed):\n",
    "    #samples: sample size\n",
    "    #features: number of positive examples, positives <= samples\n",
    "    #random_seed: initializes the random generator\n",
    "    assert positives <= samples\n",
    "    rand_state = np.random.RandomState(random_seed)\n",
    "    #values in X are from normal distribution, with zero mean, unit variance, zero covariance\n",
    "    X_pos = rand_state.randn(positives, features)\n",
    "    X_neg = rand_state.randn(samples-positives, features)+0.65\n",
    "    X = np.vstack((X_pos, X_neg))\n",
    "    #y is a randomly shuffled vector of +1 and -1 values\n",
    "    y = np.hstack((np.ones(positives), -1.*np.ones(samples-positives)))\n",
    "    I = rand_state.permutation(samples)\n",
    "    X = X[I]\n",
    "    y = y[I]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.875000\n",
      "Tux: \"Not sure if I can trust the results anymore, my data set is really small! Please help me compute the p-value!!\"\n"
     ]
    }
   ],
   "source": [
    "#20 samples, 10 features, 10 belong to positive class\n",
    "X, y = load_new_mystery_data(20, 10, 10, 10)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print(\"AUC: %f\" %cv_auc)\n",
    "print('Tux: \"Not sure if I can trust the results anymore, my data set is really small! Please help me compute the p-value!!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "Implement a permutation test for the above analysis, are these results statistically significant with $\\alpha=0.05$? Provide both visualization of the permutation distribution, as well as the p-value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement permutation\n",
    "original_auc=cv_auc #define the previous auc as \"original\" auc\n",
    "permutation_auc=[]\n",
    "\n",
    "for i in range(0,1000):\n",
    "    rand_state = np.random.RandomState(i)#create a fixed random seed for each loop\n",
    "    #=================#\n",
    "    #shuffle labels\n",
    "    y_shuffled=rand_state.permutation(y)\n",
    "    #=================#\n",
    "    #the five_fold_cv is the part used to implement cv, the same as the previous part\n",
    "    permutation_auc.append(five_fold_cv(X,y_shuffled))#un the analysis and compute the AUC value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001<0.05,the result is significant\n"
     ]
    }
   ],
   "source": [
    "#calculate the p-value of permutation test\n",
    "p_value=float(len(np.where(permutation_auc>=original_auc)[0])/1000.0)\n",
    "alpha=0.05\n",
    "if p_value < alpha:\n",
    "    print(\"{}<{},the result is significant\".format(str(p_value),str(alpha)))\n",
    "else:\n",
    "    print(\"{}>{},the result is not significant\".format(str(p_value),str(alpha)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1a15558e50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "permutation_auc=np.array(permutation_auc)\n",
    "plt.hist(permutation_auc,rwidth=0.95,alpha=0.4)\n",
    "plt.vlines(original_auc,0,200,label=str(original_auc),color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red line in the figure is that the original AUC, which is 0.875. So the right parts to the vertical line represents the 0.1% of all repetitions, means p-value is 0.001. So that these results are statistically significant with α=0.05. The model can find some connections between X and y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: mis-using feature selection\n",
    "\n",
    "Here is a very simple correlation based feature selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "def select(X, Y, scount):\n",
    "    #select scount features from X with highest correlation with Y\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = kendalltau(X[:,i], Y)[0]\n",
    "        correlations.append(np.abs(corr))\n",
    "    correlations = np.array(correlations)\n",
    "    I = np.argsort(correlations)\n",
    "    I = I[::-1]\n",
    "    return X[:,I[:scount]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tux: \"My CV-AUC before feature selection is 0.496000\"\n",
      "Tux: \"My CV-AUC after feature selection is 0.808000, it really works!!\"\n"
     ]
    }
   ],
   "source": [
    "#50 samples, 1000 features, 25 belong to positive class\n",
    "X, y = load_mystery_data(50, 1000, 25, 1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC before feature selection is %f\"' %cv_auc)\n",
    "\n",
    "\n",
    "#I'm going to improve my AUC with feature selection!!!\n",
    "X_fs = select(X, y, 5)\n",
    "cv_aucs = []\n",
    "for train, test in cv.split(X_fs, y):\n",
    "    X_train = X_fs[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X_fs[test]\n",
    "    y_test = y[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    p_test = knn.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, p_test)\n",
    "    cv_aucs.append(auc)\n",
    "cv_auc = np.mean(cv_aucs)\n",
    "print('Tux: \"My CV-AUC after feature selection is %f, it really works!!\"' %cv_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1\n",
    "\n",
    "Use permutation test to show Tux that the feature selection based classification approach is actually not learning anything from the data ($\\alpha=0.05$, provide both visualization of the permutation distribution, as well as the p-value). Running the test may take a while. Analyse what is going on here, why did the results look so good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement permutation\n",
    "original_auc=cv_auc #define the previous auc as \"original\" auc\n",
    "permutation_auc=[]\n",
    "\n",
    "\n",
    "for i in range(0,1000):\n",
    "    rand_state = np.random.RandomState(i)#create a fixed random seed for each loop\n",
    "    #=================#\n",
    "    #shuffle labels\n",
    "    y_shuffled=rand_state.permutation(y)\n",
    "    #=================#\n",
    "    #the five_fold_cv is the part used to implement cv, the same as the previous part\n",
    "    X_fs = select(X, y_shuffled, 5)\n",
    "    permutation_auc.append(five_fold_cv(X_fs,y_shuffled))#un the analysis and compute the AUC value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634>0.05,the result is not significant\n"
     ]
    }
   ],
   "source": [
    "#calculate the p-value of permutation test\n",
    "p_value=float(len(np.where(permutation_auc>=original_auc)[0])/1000.0)\n",
    "alpha=0.05\n",
    "if p_value < alpha:\n",
    "    print(\"{}<{},the result is significant\".format(str(p_value),str(alpha)))\n",
    "else:\n",
    "    print(\"{}>{},the result is not significant\".format(str(p_value),str(alpha)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1a15a74710>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "permutation_auc=np.array(permutation_auc)\n",
    "plt.hist(permutation_auc,rwidth=0.95,alpha=0.4)\n",
    "plt.vlines(original_auc,0,300,label=str(original_auc),color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is `0.634`, so that the null hypothesis should be rejected. which means that the the feature selection based classification approach learned nothing from the data. \n",
    "Also the even if for random data, the AUC is too high. This means the model is biased because it uses test data to do feature selection, which leads to over-optimistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2 (bonus exercise)\n",
    "\n",
    "Correct the bias in above example by combining feature selection properly with cross-validation, run the experiment again. Do also a permutation test for this experiment with as many permutations as you can afford in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-write the select()function to get the selected feature index \n",
    "def select(X, Y, scount):\n",
    "    #select scount features from X with highest correlation with y\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = kendalltau(X[:,i], Y)[0]\n",
    "        correlations.append(np.abs(corr))\n",
    "    correlations = np.array(correlations)\n",
    "    I = np.argsort(correlations)\n",
    "    I = I[::-1]\n",
    "    return X[:,I[:scount]],I[:scount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capsulate feature selection based cv as a function\n",
    "def fs_five_fold_cv(X,y):\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    cv_aucs = []\n",
    "    for train, test in cv.split(X, y):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_train,feature_index=select(X_train, y_train, 5)#do feature selection on training set in each round \n",
    "#         pdb.set_trace()\n",
    "        X_test = X[test][:,feature_index]\n",
    "        y_test = y[test]\n",
    "        knn = KNeighborsClassifier(n_neighbors=3)\n",
    "        knn.fit(X_train, y_train)\n",
    "        p_test = knn.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, p_test)\n",
    "        cv_aucs.append(auc)\n",
    "    cv_auc = np.mean(cv_aucs)\n",
    "    return cv_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement permutation\n",
    "X, y = load_mystery_data(50, 1000, 25, 1) #reload the data\n",
    "original_auc=fs_five_fold_cv(X,y) #define the previous auc as \"original\" auc\n",
    "permutation_auc=[]\n",
    "\n",
    "for i in range(0,1000):\n",
    "    \n",
    "    rand_state = np.random.RandomState(i)#create a fixed random seed for each loop\n",
    "    #=================#\n",
    "    #shuffle labels\n",
    "    y_shuffled=rand_state.permutation(y)\n",
    "    #=================#\n",
    "    #the five_fold_cv is the part used to implement cv, the same as the previous part\n",
    "    permutation_auc.append(fs_five_fold_cv(X,y_shuffled))#run the analysis and compute the AUC value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.513>0.05,the result is not significant\n"
     ]
    }
   ],
   "source": [
    "#calculate the p-value of permutation test\n",
    "p_value=float(len(np.where(permutation_auc>=original_auc)[0])/1000.0)\n",
    "alpha=0.05\n",
    "if p_value < alpha:\n",
    "    print(\"{}<{},the result is significant\".format(str(p_value),str(alpha)))\n",
    "else:\n",
    "    print(\"{}>{},the result is not significant\".format(str(p_value),str(alpha)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1a188b8050>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "permutation_auc=np.array(permutation_auc)\n",
    "plt.hist(permutation_auc,rwidth=0.95,alpha=0.4)\n",
    "plt.vlines(original_auc,0,300,label=str(original_auc),color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct the bias in above example by combining feature selection properly with cross-validation, run the experiment again. Do also a permutation test for this experiment with as many permutations as you can afford in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.513, and the results are not significant. We can't accept the hypothesis because this means that the model can't leanrn things from the data. But after modifying the feature selection I found that the original auc has been nearly 0.5 while results for random data are distributed unbiasedly. Compared to previous over-optimistic 0.808, I think this result should be relatively reasonable. It just shows that learning from non-signal data is difficult."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccc",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
