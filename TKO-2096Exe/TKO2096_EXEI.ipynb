{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO2096 \n",
    "## EXERCISE I\n",
    "YUE MA 520790\n",
    "\n",
    "> Use Python 3 to program your OWN implementation of k-nearest neighbors (kNN) and a way to compute cross-validation for it. The implementation should be easily modifiable, since the forthcoming exercises involve different problem-dependent variations of cross-validation.\n",
    "Select a data set from the UCI machine learning repository: http://archive.ics.uci.edu/ml/\n",
    "Use cross-validation on the training set and report the performance (e.g. classification or regression error) for different values of k\n",
    "Program a nested CV for bonus points.\n",
    "Write a report including commented code and description of the implementation ideas, description of the data set and the learning problem and your observations about the results. Return your solution for each exercise BOTH as a Jupyter Notebook .ipynb notebook and as a PDF-file made from it.\n",
    "Return the report to the course page on Monday 21. of January at the latest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data=pd.read_csv(\"/Users/mayue/Desktop/TKO-2096/Exe/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is the classical iris dataset which is usually used for learning ML.There are three attributes which describe the sepal and petal's size. The target attribute is often the \"class\" which includes three possible categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width in cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width in cm  \\\n",
       "0             5.1          3.5           1.4                0.2   \n",
       "1             4.9          3.0           1.4                0.2   \n",
       "2             4.7          3.2           1.3                0.2   \n",
       "3             4.6          3.1           1.5                0.2   \n",
       "4             5.0          3.6           1.4                0.2   \n",
       "5             5.4          3.9           1.7                0.4   \n",
       "6             4.6          3.4           1.4                0.3   \n",
       "7             5.0          3.4           1.5                0.2   \n",
       "8             4.4          2.9           1.4                0.2   \n",
       "9             4.9          3.1           1.5                0.1   \n",
       "10            5.4          3.7           1.5                0.2   \n",
       "11            4.8          3.4           1.6                0.2   \n",
       "12            4.8          3.0           1.4                0.1   \n",
       "13            4.3          3.0           1.1                0.1   \n",
       "14            5.8          4.0           1.2                0.2   \n",
       "15            5.7          4.4           1.5                0.4   \n",
       "16            5.4          3.9           1.3                0.4   \n",
       "17            5.1          3.5           1.4                0.3   \n",
       "18            5.7          3.8           1.7                0.3   \n",
       "19            5.1          3.8           1.5                0.3   \n",
       "20            5.4          3.4           1.7                0.2   \n",
       "21            5.1          3.7           1.5                0.4   \n",
       "22            4.6          3.6           1.0                0.2   \n",
       "23            5.1          3.3           1.7                0.5   \n",
       "24            4.8          3.4           1.9                0.2   \n",
       "25            5.0          3.0           1.6                0.2   \n",
       "26            5.0          3.4           1.6                0.4   \n",
       "27            5.2          3.5           1.5                0.2   \n",
       "28            5.2          3.4           1.4                0.2   \n",
       "29            4.7          3.2           1.6                0.2   \n",
       "..            ...          ...           ...                ...   \n",
       "120           6.9          3.2           5.7                2.3   \n",
       "121           5.6          2.8           4.9                2.0   \n",
       "122           7.7          2.8           6.7                2.0   \n",
       "123           6.3          2.7           4.9                1.8   \n",
       "124           6.7          3.3           5.7                2.1   \n",
       "125           7.2          3.2           6.0                1.8   \n",
       "126           6.2          2.8           4.8                1.8   \n",
       "127           6.1          3.0           4.9                1.8   \n",
       "128           6.4          2.8           5.6                2.1   \n",
       "129           7.2          3.0           5.8                1.6   \n",
       "130           7.4          2.8           6.1                1.9   \n",
       "131           7.9          3.8           6.4                2.0   \n",
       "132           6.4          2.8           5.6                2.2   \n",
       "133           6.3          2.8           5.1                1.5   \n",
       "134           6.1          2.6           5.6                1.4   \n",
       "135           7.7          3.0           6.1                2.3   \n",
       "136           6.3          3.4           5.6                2.4   \n",
       "137           6.4          3.1           5.5                1.8   \n",
       "138           6.0          3.0           4.8                1.8   \n",
       "139           6.9          3.1           5.4                2.1   \n",
       "140           6.7          3.1           5.6                2.4   \n",
       "141           6.9          3.1           5.1                2.3   \n",
       "142           5.8          2.7           5.1                1.9   \n",
       "143           6.8          3.2           5.9                2.3   \n",
       "144           6.7          3.3           5.7                2.5   \n",
       "145           6.7          3.0           5.2                2.3   \n",
       "146           6.3          2.5           5.0                1.9   \n",
       "147           6.5          3.0           5.2                2.0   \n",
       "148           6.2          3.4           5.4                2.3   \n",
       "149           5.9          3.0           5.1                1.8   \n",
       "\n",
       "              class  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "5       Iris-setosa  \n",
       "6       Iris-setosa  \n",
       "7       Iris-setosa  \n",
       "8       Iris-setosa  \n",
       "9       Iris-setosa  \n",
       "10      Iris-setosa  \n",
       "11      Iris-setosa  \n",
       "12      Iris-setosa  \n",
       "13      Iris-setosa  \n",
       "14      Iris-setosa  \n",
       "15      Iris-setosa  \n",
       "16      Iris-setosa  \n",
       "17      Iris-setosa  \n",
       "18      Iris-setosa  \n",
       "19      Iris-setosa  \n",
       "20      Iris-setosa  \n",
       "21      Iris-setosa  \n",
       "22      Iris-setosa  \n",
       "23      Iris-setosa  \n",
       "24      Iris-setosa  \n",
       "25      Iris-setosa  \n",
       "26      Iris-setosa  \n",
       "27      Iris-setosa  \n",
       "28      Iris-setosa  \n",
       "29      Iris-setosa  \n",
       "..              ...  \n",
       "120  Iris-virginica  \n",
       "121  Iris-virginica  \n",
       "122  Iris-virginica  \n",
       "123  Iris-virginica  \n",
       "124  Iris-virginica  \n",
       "125  Iris-virginica  \n",
       "126  Iris-virginica  \n",
       "127  Iris-virginica  \n",
       "128  Iris-virginica  \n",
       "129  Iris-virginica  \n",
       "130  Iris-virginica  \n",
       "131  Iris-virginica  \n",
       "132  Iris-virginica  \n",
       "133  Iris-virginica  \n",
       "134  Iris-virginica  \n",
       "135  Iris-virginica  \n",
       "136  Iris-virginica  \n",
       "137  Iris-virginica  \n",
       "138  Iris-virginica  \n",
       "139  Iris-virginica  \n",
       "140  Iris-virginica  \n",
       "141  Iris-virginica  \n",
       "142  Iris-virginica  \n",
       "143  Iris-virginica  \n",
       "144  Iris-virginica  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width in cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width in cm\n",
       "0             5.1          3.5           1.4                0.2\n",
       "1             4.9          3.0           1.4                0.2\n",
       "2             4.7          3.2           1.3                0.2\n",
       "3             4.6          3.1           1.5                0.2\n",
       "4             5.0          3.6           1.4                0.2\n",
       "5             5.4          3.9           1.7                0.4\n",
       "6             4.6          3.4           1.4                0.3\n",
       "7             5.0          3.4           1.5                0.2\n",
       "8             4.4          2.9           1.4                0.2\n",
       "9             4.9          3.1           1.5                0.1\n",
       "10            5.4          3.7           1.5                0.2\n",
       "11            4.8          3.4           1.6                0.2\n",
       "12            4.8          3.0           1.4                0.1\n",
       "13            4.3          3.0           1.1                0.1\n",
       "14            5.8          4.0           1.2                0.2\n",
       "15            5.7          4.4           1.5                0.4\n",
       "16            5.4          3.9           1.3                0.4\n",
       "17            5.1          3.5           1.4                0.3\n",
       "18            5.7          3.8           1.7                0.3\n",
       "19            5.1          3.8           1.5                0.3\n",
       "20            5.4          3.4           1.7                0.2\n",
       "21            5.1          3.7           1.5                0.4\n",
       "22            4.6          3.6           1.0                0.2\n",
       "23            5.1          3.3           1.7                0.5\n",
       "24            4.8          3.4           1.9                0.2\n",
       "25            5.0          3.0           1.6                0.2\n",
       "26            5.0          3.4           1.6                0.4\n",
       "27            5.2          3.5           1.5                0.2\n",
       "28            5.2          3.4           1.4                0.2\n",
       "29            4.7          3.2           1.6                0.2\n",
       "..            ...          ...           ...                ...\n",
       "120           6.9          3.2           5.7                2.3\n",
       "121           5.6          2.8           4.9                2.0\n",
       "122           7.7          2.8           6.7                2.0\n",
       "123           6.3          2.7           4.9                1.8\n",
       "124           6.7          3.3           5.7                2.1\n",
       "125           7.2          3.2           6.0                1.8\n",
       "126           6.2          2.8           4.8                1.8\n",
       "127           6.1          3.0           4.9                1.8\n",
       "128           6.4          2.8           5.6                2.1\n",
       "129           7.2          3.0           5.8                1.6\n",
       "130           7.4          2.8           6.1                1.9\n",
       "131           7.9          3.8           6.4                2.0\n",
       "132           6.4          2.8           5.6                2.2\n",
       "133           6.3          2.8           5.1                1.5\n",
       "134           6.1          2.6           5.6                1.4\n",
       "135           7.7          3.0           6.1                2.3\n",
       "136           6.3          3.4           5.6                2.4\n",
       "137           6.4          3.1           5.5                1.8\n",
       "138           6.0          3.0           4.8                1.8\n",
       "139           6.9          3.1           5.4                2.1\n",
       "140           6.7          3.1           5.6                2.4\n",
       "141           6.9          3.1           5.1                2.3\n",
       "142           5.8          2.7           5.1                1.9\n",
       "143           6.8          3.2           5.9                2.3\n",
       "144           6.7          3.3           5.7                2.5\n",
       "145           6.7          3.0           5.2                2.3\n",
       "146           6.3          2.5           5.0                1.9\n",
       "147           6.5          3.0           5.2                2.0\n",
       "148           6.2          3.4           5.4                2.3\n",
       "149           5.9          3.0           5.1                1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function has been defined to predict AN INSTANCE's class according to the training set. This part refered to the book:\n",
    "*Harrington, P. (2012). Machine learning in action. Shelter Island, NY: Manning Publications Co.*\n",
    "The distance metric is euclidean distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"define the function for K-NN \"\"\"\n",
    "\"\"\"Harrington, P. (2012). Machine learning in action. Shelter Island, NY: Manning Publications Co.\"\"\"\n",
    "def KNN_predict(dataSet,targets,inX,num_neighbors=3):\n",
    "    \"\"\"dataSet is the data used for training\"\"\"\n",
    "    \"\"\"targets is the labels of the training data\"\"\"\n",
    "    \"\"\"inX is the INSTANCE to be predicted\"\"\"\n",
    "    \"\"\"output: predicted label for the instance\"\"\"\n",
    "    #calculate the distance\n",
    "    size=dataSet.shape[0]\n",
    "    diffMat=np.tile(inX, (size,1))-dataSet\n",
    "#     pdb.set_trace()\n",
    "    sqDiffMat=diffMat**2\n",
    "    sqDistances=sqDiffMat.sum(axis=1)\n",
    "    distances=sqDistances**0.5\n",
    "    sortedDistanceIndices=distances.argsort()\n",
    "    classCount={}\n",
    "    for i in range(num_neighbors):\n",
    "        voteIlabel=targets[sortedDistanceIndices[i]]\n",
    "        classCount[voteIlabel]=classCount.get(voteIlabel,0)+1\n",
    "    sortedClassCount=sorted(classCount.iteritems(),\n",
    "                           key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import zscore\n",
    "\"\"\"Data preprocessing,normalization\"\"\"\n",
    "iris_attributes=np.array(iris_data.iloc[:,0:4])\n",
    "iris_attributes=zscore(iris_attributes)#normalization\n",
    "iris_targets=np.array(iris_data['class'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_attributes,iris_targets,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the part used to preprocess data. For convenience I just used the scipy and sklearn's function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validate(attributes,targets,predictor,num_fold=3):\n",
    "    \"\"\"launch a k-fold CV on given training set and use the given predictor\"\"\"\n",
    "    \"\"\"attributes:training set attributes\"\"\"\n",
    "    \"\"\"targets:labels of training set\"\"\"\n",
    "    \"\"\"predictors: function to be validated\"\"\"\n",
    "    \"\"\"output:a DataFrame which show the score results\"\"\"\n",
    "    m=attributes.shape[0]\n",
    "    size_fold=m/num_fold\n",
    "    score={}\n",
    "    used_validation_instances=[]#store the used validation instances' indice to avoid repeatly using\n",
    "    \n",
    "    for k in range(1,num_fold+1):\n",
    "#         pdb.set_trace()\n",
    "        validate_indices=np.random.choice(list(set(range(0,m))-set(used_validation_instances)),size_fold,replace=False)#randomly select the instances from REMAIN instances       \n",
    "        train_indices=np.array(list(set(range(0,m))-set(validate_indices)))       \n",
    "        used_validation_instances+=validate_indices.tolist()#add used validation instances into the list\n",
    "        \n",
    "        count_correct=[]\n",
    "        for indice in validate_indices:\n",
    "            pred=KNN_predict(attributes[train_indices],targets[train_indices],attributes[indice],num_neighbors=3)\n",
    "            if pred==targets[indice]:\n",
    "                count_correct.append(1)\n",
    "            else:\n",
    "                count_correct.append(0)\n",
    "#         pdb.set_trace()\n",
    "        score[str(k)]=(sum(count_correct)/float(size_fold))\n",
    "    \n",
    "    result=pd.DataFrame.from_dict(score,orient='index',columns=['score'])\n",
    "    result.index=result.index.astype(\"int\")\n",
    "    result=result.sort_index()#re-arrange the order of results\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "1   0.933333\n",
       "2   1.000000\n",
       "3   0.866667\n",
       "4   0.933333\n",
       "5   0.933333\n",
       "6   0.866667\n",
       "7   0.933333\n",
       "8   1.000000\n",
       "9   1.000000\n",
       "10  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CV_result_1=k_fold_cross_validate(iris_attributes,iris_targets,KNN_predict,10)\n",
    "display(CV_result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar([str(i) for i in CV_result_1.index.tolist()],CV_result_1.iloc[:,0])\n",
    "plt.xlabel(\"fold\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code above has constructed a function for k-fold cross validation. It accepts the training set and function used to predict and parameter k(default equals to 3).\n",
    "- the score part has not been packaged and now it is for classfication accuracy. If necessary I should create the function of scoring to make the CV easier to be modified.\n",
    "- the predictor is not an object but a function, so parameter should be set in CV (or just follow the default option), for this case, k for KNN is 3.\n",
    "- From the visualized results we can see that the accuracy is relatively high and the model perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Using sklearn to compare the results of CV\"\"\"\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_attributes,iris_targets,test_size=0.33, random_state=42)\n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "CV_results_sklearn=cross_val_score(knn, X_train, y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([str(i) for i in range(1,11)],CV_results_sklearn)\n",
    "plt.xlabel(\"fold\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I have used sklearn to launch a 10-fold CV, and the accuracy is also relatively high. Considering the Randomness of selecting data, these two CV results can be regarded as SIMILIAR results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "To complete the bonus work, I have found that I have to refactor the previous code by object-based way. But I decide to not re-write parts above in case there is any error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Classfier():\n",
    "    \"\"\"set the hyper parameter K\"\"\"\n",
    "    def __init__(self,num_neighbors=3):\n",
    "        self.num_neighbors=num_neighbors\n",
    "        \n",
    "    def fit(self,attributes,targets):\n",
    "        \"\"\"let the classfier 'memorize' the trainset\"\"\"\n",
    "        \"\"\"attributes and targets are arrays\"\"\"\n",
    "        self.attributes=attributes\n",
    "        self.targets=targets\n",
    "        \n",
    "    def predict(self,inX):\n",
    "        \"\"\"predict an input instance's label \"\"\"\n",
    "        \"\"\"inX is an 1-d array which represents an instance\"\"\"\n",
    "        size=self.attributes.shape[0]\n",
    "        diffMat=np.tile(inX, (size,1))-self.attributes\n",
    "#     pdb.set_trace()\n",
    "        sqDiffMat=diffMat**2\n",
    "        sqDistances=sqDiffMat.sum(axis=1)\n",
    "        distances=sqDistances**0.5\n",
    "        sortedDistanceIndices=distances.argsort()\n",
    "        classCount={}\n",
    "        for i in range(self.num_neighbors):\n",
    "            voteIlabel=self.targets[sortedDistanceIndices[i]]\n",
    "            classCount[voteIlabel]=classCount.get(voteIlabel,0)+1\n",
    "        sortedClassCount=sorted(classCount.iteritems(),\n",
    "                               key=operator.itemgetter(1),reverse=True)\n",
    "        return sortedClassCount[0][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_scorer(predictor,X,y):\n",
    "    \"\"\"predictor object should have been fitted to the train data\"\"\"\n",
    "    \"\"\"X,y (np.array) are dataset used to test the predictor\"\"\"\n",
    "    count_correct=[]\n",
    "#     pdb.set_trace()\n",
    "    for inX,iny in zip(X,y):\n",
    "        #predict for each instance\n",
    "        pred=predictor.predict(inX)\n",
    "        if pred==iny:\n",
    "            count_correct.append(1)\n",
    "        else:\n",
    "            count_correct.append(0)\n",
    "    score=float(sum(count_correct)/float(X.shape[0]))\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nested_CV():\n",
    "    def __init__(self,num_fold=10):\n",
    "        self.num_fold=num_fold\n",
    "        \n",
    "    def load_data(self,attributes,targets):\n",
    "        \"\"\"load the train data before validating\"\"\"\n",
    "        self.attributes=attributes\n",
    "        self.targets=targets\n",
    "        \n",
    "    def cv_eval(self,predictor_class,scorer,hyper_parameter_values):\n",
    "        \"\"\"predictor should be a CLASS\"\"\"\n",
    "        \"\"\"scorer is the function used to evaluate the predictor\"\"\"\n",
    "        \"\"\"hyper_parameter:a dict, {'parameter_name':[value1,value2]}\"\"\"\n",
    "        \"\"\"calculate the validation results and the best value which produce the best performance\"\"\"\n",
    "        m=self.attributes.shape[0]\n",
    "        size_fold=m/self.num_fold\n",
    "        hp_scores={}\n",
    "\n",
    "        hp=hyper_parameter_values.keys()[0]#get the name of the parameter\n",
    "        for hv in hyper_parameter_values.values()[0]:\n",
    "            \n",
    "            predictor=predictor_class(hv)\n",
    "            scores=[]\n",
    "            used_validation_instances=[]\n",
    "#             pdb.set_trace()\n",
    "            for k in range(1,self.num_fold+1):\n",
    "                validate_indices=np.random.choice(list(set(range(0,m))-set(used_validation_instances)),size_fold,replace=False)#randomly select the instances from REMAIN instances       \n",
    "                train_indices=np.array(list(set(range(0,m))-set(validate_indices)))       \n",
    "                used_validation_instances+=validate_indices.tolist()#add used validation instances into the list\n",
    "                X_train=self.attributes[train_indices]\n",
    "                y_train=self.targets[train_indices]\n",
    "                predictor.fit(X_train,y_train)\n",
    "                scores.append(scorer(predictor,\n",
    "                                     self.attributes[validate_indices],\n",
    "                                     self.targets[validate_indices]))\n",
    "            hp_scores[str(hv)]=np.mean(scores)\n",
    "        result=pd.DataFrame.from_dict(hp_scores,orient='index',columns=['score'])\n",
    "        self.result=result\n",
    "        self.best_value=result.idxmax().iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best value of K is 5\n"
     ]
    }
   ],
   "source": [
    "cccv=Nested_CV(10)\n",
    "cccv.load_data(X_train,y_train)\n",
    "cccv.cv_eval(KNN_Classfier,accuracy_scorer,{'num_neighbors':[1,2,3,4,5,6,7,8]})\n",
    "CV_result_3=cccv.result\n",
    "print(\"the best value of K is {}\".format(cccv.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'score')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([str(i) for i in CV_result_3.index.tolist()],CV_result_3.iloc[:,0])\n",
    "plt.xlabel(\"number of neighbors\")\n",
    "plt.ylabel(\"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I have refered the sklearn's way of building a predictor class. The predictor should firstly have its parameters set, then be fitted to the given data set. \n",
    "\n",
    "Nested cross validation part is also encapsulated as a class, and it can be combined with predictor class and scorer. This way is also similar to sklearn's. I think this library has provided a good way to encapsulate the cross validation. Even though I am coding my own CV class I can't ignore its solution.\n",
    "\n",
    "The outer loop of CV tries different parameter values, and inner loop calculate k-fold CV score for each parameter values. Each parameter value's score is given by calculating each inner loop's mean score. Then the parameter value which produce the highest score is the one we want."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccc",
   "language": "python",
   "name": "ccc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
