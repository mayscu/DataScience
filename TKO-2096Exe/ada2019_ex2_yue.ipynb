{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO2096 \n",
    "## EXERCISE II Prediction of the metal ion content from multi-parameter data\n",
    "YUE MA 520790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import operator\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_data=pd.read_csv(\"/Users/mayue/Desktop/TKO-2096/Exe/Water_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_total</th>\n",
       "      <th>Cd</th>\n",
       "      <th>Pb</th>\n",
       "      <th>Mod1</th>\n",
       "      <th>Mod2</th>\n",
       "      <th>Mod3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9945</td>\n",
       "      <td>119</td>\n",
       "      <td>72335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10786</td>\n",
       "      <td>117</td>\n",
       "      <td>82977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10812</td>\n",
       "      <td>120</td>\n",
       "      <td>98594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9742</td>\n",
       "      <td>127</td>\n",
       "      <td>154323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10566</td>\n",
       "      <td>108</td>\n",
       "      <td>136416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8495</td>\n",
       "      <td>120</td>\n",
       "      <td>131672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>2.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>10400</td>\n",
       "      <td>134</td>\n",
       "      <td>96528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>2.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>8298</td>\n",
       "      <td>113</td>\n",
       "      <td>99239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>2.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>8563</td>\n",
       "      <td>130</td>\n",
       "      <td>113979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>9879</td>\n",
       "      <td>130</td>\n",
       "      <td>87882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>10412</td>\n",
       "      <td>101</td>\n",
       "      <td>95515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>12605</td>\n",
       "      <td>130</td>\n",
       "      <td>125010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>19491</td>\n",
       "      <td>133</td>\n",
       "      <td>186314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>18774</td>\n",
       "      <td>118</td>\n",
       "      <td>120807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>26959</td>\n",
       "      <td>143</td>\n",
       "      <td>157330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23158</td>\n",
       "      <td>123</td>\n",
       "      <td>145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>16340</td>\n",
       "      <td>129</td>\n",
       "      <td>112713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>16957</td>\n",
       "      <td>138</td>\n",
       "      <td>153859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23429</td>\n",
       "      <td>136</td>\n",
       "      <td>62430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34946</td>\n",
       "      <td>277</td>\n",
       "      <td>77537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35559</td>\n",
       "      <td>332</td>\n",
       "      <td>81046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9769</td>\n",
       "      <td>134</td>\n",
       "      <td>135117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10692</td>\n",
       "      <td>151</td>\n",
       "      <td>136432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11632</td>\n",
       "      <td>138</td>\n",
       "      <td>127901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11356</td>\n",
       "      <td>140</td>\n",
       "      <td>19534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9951</td>\n",
       "      <td>134</td>\n",
       "      <td>150528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9785</td>\n",
       "      <td>138</td>\n",
       "      <td>159554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12939</td>\n",
       "      <td>133</td>\n",
       "      <td>108785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16265</td>\n",
       "      <td>185</td>\n",
       "      <td>127914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16802</td>\n",
       "      <td>195</td>\n",
       "      <td>128542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2000</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>128478</td>\n",
       "      <td>2255</td>\n",
       "      <td>7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2000</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>126430</td>\n",
       "      <td>2604</td>\n",
       "      <td>6996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2000</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>127269</td>\n",
       "      <td>2453</td>\n",
       "      <td>7420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>84983</td>\n",
       "      <td>1514</td>\n",
       "      <td>5585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>84277</td>\n",
       "      <td>1421</td>\n",
       "      <td>6016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>88741</td>\n",
       "      <td>1500</td>\n",
       "      <td>6877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>75190</td>\n",
       "      <td>2646</td>\n",
       "      <td>19907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>75190</td>\n",
       "      <td>2638</td>\n",
       "      <td>18963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>73922</td>\n",
       "      <td>2726</td>\n",
       "      <td>20179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65458</td>\n",
       "      <td>6253</td>\n",
       "      <td>113682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65300</td>\n",
       "      <td>6456</td>\n",
       "      <td>110420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63538</td>\n",
       "      <td>6264</td>\n",
       "      <td>123407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>17240</td>\n",
       "      <td>5518</td>\n",
       "      <td>6089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>18075</td>\n",
       "      <td>4491</td>\n",
       "      <td>6193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19213</td>\n",
       "      <td>5845</td>\n",
       "      <td>5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>5000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>28833</td>\n",
       "      <td>5698</td>\n",
       "      <td>5754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>5000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>28833</td>\n",
       "      <td>5577</td>\n",
       "      <td>5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>5000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>30024</td>\n",
       "      <td>4490</td>\n",
       "      <td>5580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>5000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>32024</td>\n",
       "      <td>2498</td>\n",
       "      <td>4227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>5000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>32547</td>\n",
       "      <td>2490</td>\n",
       "      <td>4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>33129</td>\n",
       "      <td>2523</td>\n",
       "      <td>4398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>5000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>20515</td>\n",
       "      <td>1082</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>5000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>22528</td>\n",
       "      <td>910</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>5000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>23237</td>\n",
       "      <td>968</td>\n",
       "      <td>2166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>22396</td>\n",
       "      <td>563</td>\n",
       "      <td>7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>22396</td>\n",
       "      <td>1692</td>\n",
       "      <td>6023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>5000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>22262</td>\n",
       "      <td>1446</td>\n",
       "      <td>5923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22633</td>\n",
       "      <td>4527</td>\n",
       "      <td>127464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22655</td>\n",
       "      <td>4467</td>\n",
       "      <td>144188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23331</td>\n",
       "      <td>4241</td>\n",
       "      <td>140303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     c_total      Cd      Pb    Mod1  Mod2    Mod3\n",
       "0          0     0.0     0.0    9945   119   72335\n",
       "1          0     0.0     0.0   10786   117   82977\n",
       "2          0     0.0     0.0   10812   120   98594\n",
       "3         14     0.0    14.0    9742   127  154323\n",
       "4         14     0.0    14.0   10566   108  136416\n",
       "5         14     0.0    14.0    8495   120  131672\n",
       "6         14     2.8    11.2   10400   134   96528\n",
       "7         14     2.8    11.2    8298   113   99239\n",
       "8         14     2.8    11.2    8563   130  113979\n",
       "9         14     5.6     8.4    9879   130   87882\n",
       "10        14     5.6     8.4   10412   101   95515\n",
       "11        14     5.6     8.4   12605   130  125010\n",
       "12        14     8.4     5.6   19491   133  186314\n",
       "13        14     8.4     5.6   18774   118  120807\n",
       "14        14     8.4     5.6   26959   143  157330\n",
       "15        14    11.2     2.8   23158   123  145455\n",
       "16        14    11.2     2.8   16340   129  112713\n",
       "17        14    11.2     2.8   16957   138  153859\n",
       "18        14    14.0     0.0   23429   136   62430\n",
       "19        14    14.0     0.0   34946   277   77537\n",
       "20        14    14.0     0.0   35559   332   81046\n",
       "21        20     0.0    20.0    9769   134  135117\n",
       "22        20     0.0    20.0   10692   151  136432\n",
       "23        20     0.0    20.0   11632   138  127901\n",
       "24        20     4.0    16.0   11356   140   19534\n",
       "25        20     4.0    16.0    9951   134  150528\n",
       "26        20     4.0    16.0    9785   138  159554\n",
       "27        20     8.0    12.0   12939   133  108785\n",
       "28        20     8.0    12.0   16265   185  127914\n",
       "29        20     8.0    12.0   16802   195  128542\n",
       "..       ...     ...     ...     ...   ...     ...\n",
       "171     2000   800.0  1200.0  128478  2255    7269\n",
       "172     2000   800.0  1200.0  126430  2604    6996\n",
       "173     2000   800.0  1200.0  127269  2453    7420\n",
       "174     2000  1200.0   800.0   84983  1514    5585\n",
       "175     2000  1200.0   800.0   84277  1421    6016\n",
       "176     2000  1200.0   800.0   88741  1500    6877\n",
       "177     2000  1600.0   400.0   75190  2646   19907\n",
       "178     2000  1600.0   400.0   75190  2638   18963\n",
       "179     2000  1600.0   400.0   73922  2726   20179\n",
       "180     2000  2000.0     0.0   65458  6253  113682\n",
       "181     2000  2000.0     0.0   65300  6456  110420\n",
       "182     2000  2000.0     0.0   63538  6264  123407\n",
       "183     5000     0.0  5000.0   17240  5518    6089\n",
       "184     5000     0.0  5000.0   18075  4491    6193\n",
       "185     5000     0.0  5000.0   19213  5845    5347\n",
       "186     5000  1000.0  4000.0   28833  5698    5754\n",
       "187     5000  1000.0  4000.0   28833  5577    5399\n",
       "188     5000  1000.0  4000.0   30024  4490    5580\n",
       "189     5000  2000.0  3000.0   32024  2498    4227\n",
       "190     5000  2000.0  3000.0   32547  2490    4065\n",
       "191     5000  2000.0  3000.0   33129  2523    4398\n",
       "192     5000  3000.0  2000.0   20515  1082    2153\n",
       "193     5000  3000.0  2000.0   22528   910    2174\n",
       "194     5000  3000.0  2000.0   23237   968    2166\n",
       "195     5000  4000.0  1000.0   22396   563    7454\n",
       "196     5000  4000.0  1000.0   22396  1692    6023\n",
       "197     5000  4000.0  1000.0   22262  1446    5923\n",
       "198     5000  5000.0     0.0   22633  4527  127464\n",
       "199     5000  5000.0     0.0   22655  4467  144188\n",
       "200     5000  5000.0     0.0   23331  4241  140303\n",
       "\n",
       "[201 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(water_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"split the data into attributes and targets\"\"\"\n",
    "y=water_data.iloc[:,0:3]\n",
    "X=water_data.iloc[:,3:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"normalize the data\"\"\"\n",
    "from scipy.stats import zscore\n",
    "y=zscore(y)\n",
    "X=zscore(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"split data into train set and test set\"\"\"\n",
    "# n=water_data.shape[0]\n",
    "# m=150 #the number of train instances\n",
    "# X_train=X[0:m,:]\n",
    "# y_train=y[0:m,:]\n",
    "# X_test=X[m:n,:]\n",
    "# y_test=y[m:n,:]\n",
    "# print(X_train.shape[0],X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"randomly split data into train set and test set\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Regression():\n",
    "    \"\"\"set the hyper parameter K\"\"\"\n",
    "    def __init__(self,num_neighbors=3):\n",
    "        self.num_neighbors=num_neighbors\n",
    "        \n",
    "    def fit(self,attributes,targets):\n",
    "        \"\"\"let the classfier 'memorize' the trainset\"\"\"\n",
    "        \"\"\"attributes and targets are arrays\"\"\"\n",
    "        self.attributes=attributes\n",
    "        self.all_targets=targets #store the copy of all different kinds of labels\n",
    "        self.targets=targets#labels we want to predict for now\n",
    "        \n",
    "        \n",
    "    def predict(self,inX):\n",
    "        \"\"\"predict an input instance's label \"\"\"\n",
    "        \"\"\"inX is an 1-d array which represents an instance\"\"\"\n",
    "        size=self.attributes.shape[0]\n",
    "        diffMat=np.tile(inX, (size,1))-self.attributes\n",
    "#     pdb.set_trace()\n",
    "        sqDiffMat=diffMat**2\n",
    "        sqDistances=sqDiffMat.sum(axis=1)\n",
    "        distances=sqDistances**0.5\n",
    "        sortedDistanceIndices=distances.argsort()\n",
    "        valueCount=[]\n",
    "        for i in range(self.num_neighbors):\n",
    "            voteIvalue=self.targets[sortedDistanceIndices[i]]\n",
    "            valueCount.append(voteIvalue)\n",
    "        predictedValue=np.mean(valueCount)\n",
    "        return predictedValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Regression_Multi(KNN_Regression):\n",
    "\n",
    "\n",
    "    def select_label(self,indice):\n",
    "        \"\"\"fit the model using selected labels\"\"\"\n",
    "        self.targets=self.all_targets[:,indice]\n",
    "        \n",
    "    def predict_multi(self,inX,label_index):\n",
    "        \"\"\"predict for multi label values,return a list of predicted values\"\"\"\n",
    "        \"\"\"label_indice: a list of index of labels to be predicted\"\"\"\n",
    "        n=self.all_targets.shape[1]\n",
    "        pred=[]\n",
    "        for i in label_index:\n",
    "            self.select_label(i)#change the label to be predicted\n",
    "            pred.append(self.predict(inX))\n",
    "        return pred\n",
    "    \n",
    "    def predict_ion(self,inX):\n",
    "        \"\"\"this function is to solve the specific requirement of the case, where one lable c_total is the sum of other 2 labels\"\"\"\n",
    "        pred=[]\n",
    "        temp=self.predict_multi(inX,[1,2])\n",
    "        pred.append(temp[0])\n",
    "        pred.append(temp[1])\n",
    "#         pdb.set_trace()\n",
    "        pred.append(sum(pred))\n",
    "        pred=[pred[2],pred[0],pred[1]] #arrange the order of the values\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the KNN predictor works on predicting multi values, I have created a subclass of `KNN_Regression_Multi`. It can produce multi predicted values at a meanwhile.\n",
    "\n",
    "Another tricky problem I have met is that the case is special which include a label `c_total` as the sum of other labels. So I have to build a new special function to get the better predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6998895486271492, 2.120376322042721, -0.420486773415572]\n",
      "----------\n",
      "[1.0794694930823088, 2.120376322042721, -0.420486773415572]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"simplely test the model\"\"\"\n",
    "a=KNN_Regression_Multi(3)\n",
    "a.fit(X_train,y_train)\n",
    "print(a.predict_ion(X_train[1]))\n",
    "print(\"----------\")\n",
    "print(a.predict_multi(X_train[1],[0,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily find that the differences of two predicting functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the C-index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_index(pred,true_labels):\n",
    "    \"\"\"pred and true_labels are sequences which have same length\"\"\"\n",
    "    n=0\n",
    "    h_sum=0.0\n",
    "    for i in range(0,len(true_labels)):\n",
    "        t=true_labels[i]\n",
    "        p=pred[i]\n",
    "        for j in range(i+1,len(true_labels)):\n",
    "            nt=true_labels[j]\n",
    "            np=pred[j]\n",
    "            if t!=nt:\n",
    "                n=n+1\n",
    "#                 pdb.set_trace()\n",
    "                if ((p<np)&(t<nt))|((p>np)&(t>nt)):\n",
    "                    h_sum+=1.0\n",
    "                else:\n",
    "                    if p==np:\n",
    "                        h_sum+=0.5\n",
    "    return float(h_sum/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test the C_index function,the result should be 0.75\"\"\"\n",
    "C_index([0.60,0.80,0.75,0.75,0.7],[-1,1,1,-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function works because it return correct values over given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_index_scorer(predictor,X_test,y_test):\n",
    "    \"\"\"evaluate prediction performance using C—index over the data set\"\"\"\n",
    "#     results=[]\n",
    "    scores=[]\n",
    "    for inX,iny in zip(X_test,y_test):\n",
    "        pred=predictor.predict_ion(inX) #should consider the methods of the object therefore are defective\n",
    "#         pdb.set_trace()\n",
    "#         results+=pred\n",
    "        scores.append(C_index(pred,iny))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOO_CV():\n",
    "    \n",
    "    def load_data(self,attributes,targets):\n",
    "        \"\"\"load the train data before validating\"\"\"\n",
    "#         random.shuffle(attributes)\n",
    "#         random.shuffle(targets)\n",
    "        self.attributes=attributes\n",
    "        self.targets=targets\n",
    "        \n",
    "    def CV_eval(self,predictor_class,scorer,num_neighbor):\n",
    "        \"\"\"predictor_class is the predictor CLASS used to validate\"\"\"\n",
    "        \"\"\"scorer is a function used to evaluate the performance over dataset\"\"\"\n",
    "        \"\"\"num_neighbor is a contemporary parameter for this exercise, which is used to set the KNN model\"\"\"\n",
    "        \"\"\"the results of each validation are represented in a dataframe\"\"\"\n",
    "        m=self.attributes.shape[0]\n",
    "        all_results={}\n",
    "        all_scores={}\n",
    "        for i in range(0,m):\n",
    "            #split train set and validate set\n",
    "            X_validate=self.attributes[i]\n",
    "            y_validate=self.targets[i]\n",
    "            X_validate=X_validate.reshape(1,X_validate.shape[0])\n",
    "            y_validate=y_validate.reshape(1,y_validate.shape[0])#make sure they are 2-d array\n",
    "            X_train=np.delete(self.attributes,i,0)\n",
    "            y_train=np.delete(self.targets,i,0)\n",
    "#             pdb.set_trace()\n",
    "#             hp=hyper_parameter_values.keys()[0]#get the name of the parameter\n",
    "            predictor=predictor_class(num_neighbor)\n",
    "            predictor.fit(X_train,y_train)\n",
    "            pred=predictor.predict_ion(X_validate)\n",
    "            all_results[str(i)]=pred\n",
    "            all_scores[str(i)]= scorer(predictor,pred,y_validate)\n",
    "#         self.all_results=pd.DataFrame.from_dict(all_results,orient='index',columns=['c_total','cd','pb'])\n",
    "        self.all_scores=pd.DataFrame.from_dict(all_scores,orient='index',columns=['c-index'])\n",
    "        self.all_results=pd.DataFrame.from_dict(all_results,orient='index',columns=['c_total','cd','pb'])\n",
    "        return self.all_scores\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L3O_CV(LOO_CV):\n",
    "    \n",
    "    def CV_eval(self,predictor_class,scorer,num_neighbor):\n",
    "        \"\"\"predictor_class is the predictor CLASS used to validate\"\"\"\n",
    "        \"\"\"scorer is a function used to evaluate the performance over dataset\"\"\"\n",
    "        \"\"\"num_neighbor is a contemporary parameter for this exercise, which used to set the KNN model\"\"\"\n",
    "        \"\"\"the results of each validation are represented in a dataframe\"\"\"\n",
    "        m=self.attributes.shape[0]\n",
    "        all_results={}\n",
    "        all_scores={}\n",
    "        for i in range(0,m,3):\n",
    "            #split train set and validate set\n",
    "            X_validate=self.attributes[i:i+3]\n",
    "            y_validate=self.targets[i:i+3]          \n",
    "            X_train=np.delete(self.attributes,[i,i+1,i+2],0)\n",
    "            y_train=np.delete(self.targets,[i,i+1,i+2],0)\n",
    "#             pdb.set_trace()\n",
    "            predictor=predictor_class(num_neighbor)\n",
    "            predictor.fit(X_train,y_train)\n",
    "#             all_results[str(i)]=scorer(predictor,X_validate,y_validate)\n",
    "#         self.mean_score=np.mean(all_results)\n",
    "#         self.eval_results=pd.DataFrame.from_dict(all_results,orient='index',columns=['c-index_1','c-index_2','c-index_3'])\n",
    "#         return self.eval_results\n",
    "\n",
    "            all_scores[str(i)]= scorer(predictor,X_validate,y_validate)# this step is special for solving this case\n",
    "\n",
    "                \n",
    "#         self.mean_score=np.mean(all_results)\n",
    "        self.all_scores=pd.DataFrame.from_dict(all_scores,orient='index',columns=['c_total','cd','pb'])\n",
    "#         self.all_scores=pd.DataFrame.from_dict(all_scores,orient='index',columns=['c-index'])\n",
    "        return self.all_scores\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the C-index based on LOO CV and L3O CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Calculate c-index for different k values using LOO CV\"\"\"\n",
    "loo=LOO_CV()\n",
    "loo.load_data(X_train,y_train)\n",
    "\n",
    "namelist=[]\n",
    "for i in range(1,6):\n",
    "    name='loo_score_'+str(i)\n",
    "    namelist.append(name)\n",
    "    locals()[name]=loo.CV_eval(KNN_Regression_Multi,C_index_scorer,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k=1</th>\n",
       "      <th>k=2</th>\n",
       "      <th>k=3</th>\n",
       "      <th>k=4</th>\n",
       "      <th>k=5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         k=1       k=2       k=3       k=4       k=5\n",
       "11  0.333333  0.000000  0.000000  0.000000  0.000000\n",
       "10  0.333333  1.000000  1.000000  1.000000  1.000000\n",
       "13  1.000000  0.333333  0.333333  0.333333  0.333333\n",
       "12  0.333333  1.000000  1.000000  1.000000  1.000000\n",
       "15  0.666667  0.666667  0.666667  0.666667  0.666667\n",
       "14  0.000000  0.333333  0.333333  0.333333  0.333333\n",
       "17  1.000000  0.666667  1.000000  1.000000  0.666667\n",
       "16  0.666667  1.000000  0.666667  0.333333  0.333333\n",
       "19  0.666667  1.000000  0.333333  0.333333  0.333333\n",
       "18  0.333333  1.000000  1.000000  1.000000  1.000000\n",
       "1   0.000000  0.666667  0.666667  0.666667  1.000000\n",
       "0   0.666667  1.000000  1.000000  0.333333  0.333333\n",
       "3   0.333333  0.666667  0.666667  1.000000  0.666667\n",
       "2   0.333333  0.666667  0.666667  0.666667  0.666667\n",
       "5   0.666667  1.000000  0.333333  1.000000  0.333333\n",
       "4   0.666667  0.000000  0.000000  0.000000  0.000000\n",
       "7   0.333333  1.000000  1.000000  1.000000  1.000000\n",
       "6   0.666667  1.000000  0.666667  0.333333  0.333333\n",
       "9   0.666667  1.000000  0.333333  1.000000  0.333333\n",
       "8   0.333333  1.000000  1.000000  0.666667  0.666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_scores=pd.concat([loo_score_1,loo_score_2,loo_score_3,loo_score_4,loo_score_5],axis=1)\n",
    "loo_scores.columns=['k=1','k=2','k=3','k=4','k=5']\n",
    "loo_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k=1    0.500000\n",
       "k=2    0.750000\n",
       "k=3    0.633333\n",
       "k=4    0.633333\n",
       "k=5    0.550000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "firstly output the all c-index results using LOO. When k=2 there should a best performance for the given KNN regression model. To get the unbiased result, I set the k=1 and test this model over new data, which is the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569060773480663"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_best=KNN_Regression_Multi(num_neighbors=2)\n",
    "loo_best.fit(X_train,y_train)\n",
    "np.mean(C_index_scorer(loo_best,X_test,y_test))#the performance of best model over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayue/anaconda3/envs/ccc/lib/python2.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/mayue/anaconda3/envs/ccc/lib/python2.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">k=1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">k=2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">k=3</th>\n",
       "      <th colspan=\"3\" halign=\"left\">k=4</th>\n",
       "      <th colspan=\"3\" halign=\"left\">k=5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         k=1                           k=2                           k=3  \\\n",
       "          C1        C2        C3        C1        C2        C3        C1   \n",
       "12  0.333333  0.666667  0.333333  0.500000  0.666667  0.333333  0.666667   \n",
       "15  1.000000  1.000000  0.666667  1.000000  1.000000  0.666667  1.000000   \n",
       "18  0.666667  1.000000       NaN  0.666667  1.000000       NaN  0.666667   \n",
       "0   1.000000  0.333333  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "3   1.000000  0.333333  1.000000  0.666667  0.333333  1.000000  0.666667   \n",
       "6   1.000000  0.000000  0.666667  0.333333  0.000000  0.666667  0.333333   \n",
       "9   1.000000  0.666667  0.333333  1.000000  0.666667  0.333333  1.000000   \n",
       "\n",
       "                             k=4                           k=5            \\\n",
       "          C2        C3        C1        C2        C3        C1        C2   \n",
       "12  0.666667  0.333333  1.000000  0.666667  0.333333  1.000000  0.666667   \n",
       "15  0.333333  0.666667  1.000000  0.333333  0.666667  1.000000  0.333333   \n",
       "18  0.333333       NaN  0.666667  0.333333       NaN  1.000000  0.666667   \n",
       "0   1.000000  1.000000  0.333333  1.000000  1.000000  0.333333  1.000000   \n",
       "3   0.333333  1.000000  0.666667  0.000000  1.000000  0.666667  0.000000   \n",
       "6   0.333333  0.666667  0.333333  0.333333  0.666667  0.333333  0.333333   \n",
       "9   0.666667  0.000000  1.000000  0.666667  0.333333  0.333333  0.666667   \n",
       "\n",
       "              \n",
       "          C3  \n",
       "12  0.333333  \n",
       "15  0.666667  \n",
       "18       NaN  \n",
       "0   1.000000  \n",
       "3   0.333333  \n",
       "6   0.666667  \n",
       "9   0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Calculate c-index for different k values using L3O CV\"\"\"\n",
    "l3o=L3O_CV()\n",
    "l3o.load_data(X_train,y_train)\n",
    "\n",
    "namelist=[]\n",
    "for i in range(1,6):\n",
    "    name='l3o_score_'+str(i)\n",
    "    namelist.append(name)\n",
    "    locals()[name]=l3o.CV_eval(KNN_Regression_Multi,C_index_scorer,i)\n",
    "\n",
    "l3o_scores=pd.concat([l3o_score_1,l3o_score_2,l3o_score_3,l3o_score_4,l3o_score_5],axis=1)\n",
    "l3o_scores.columns=[['k=1','k=1','k=1','k=2','k=2','k=2','k=3','k=3','k=3','k=4','k=4','k=4','k=5','k=5','k=5'],['C1','C2','C3','C1','C2','C3','C1','C2','C3','C1','C2','C3','C1','C2','C3']]\n",
    "display(l3o_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1    0.706349\n",
      "k=2    0.698413\n",
      "k=3    0.626984\n",
      "k=4    0.611111\n",
      "k=5    0.579365\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "l3o_scores_mean=l3o_scores.mean(axis=1,level=0).mean()\n",
    "print(l3o_scores_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k=1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3o_scores_mean.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then produce the results of L3O. We can find that averagely this CV gets better performance on train set than LOO. And for this evaluation approach, the best k should be 1, the same as LOO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808471454880295"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3o_best=KNN_Regression_Multi(1)\n",
    "l3o_best.fit(X_train,y_train)\n",
    "np.mean(C_index_scorer(l3o_best,X_test,y_test))#the performance of best model over test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A tricky problem for me here is that how I should use the C-index. This is to say, Should I calculate predicted labels and true labels for each instance, or should I calculte all the predicted values and all true values as for EACH SINGLE label? I have tried both, and the present version may be the solution most suited to the question.\n",
    "- Firstly I want to make CV as more non-specifical as possible, but it is very difficult. So some steps here have not been encapsulated perfectly. I will try to imporve this point in the follow-up exercises.\n",
    "-  I have guessed that L3O should generalize better. Actually LOO gets worse perfermance on train data than L3O. The reason here might be that validating model on three samples once will make the score more biased than on only one sample.\n",
    "- For test data, LOO's best model has worse performance than L3O's best model. This means for this case L3O generalize better than LOO\n",
    "- But I can' t simply conclude that who generalize better because the data is not enough. I have tried different proportion of test set and results differ.\n",
    "- Intuitively I think the evaluation of L3O might be more stable because it validate on more instances thefore avoids contingency more, which will also make scores optimisticly biased sometimes. For this exercise there are copies for samples, this may make the results influenced ,too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccc",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
