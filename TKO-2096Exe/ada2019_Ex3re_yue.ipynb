{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO2096 \n",
    "## EXERCISE III | Pain assessment from biosignal data\n",
    "YUE MA 520790"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from scipy.stats import zscore\n",
    "import operator\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main used libraries\n",
    "- `sklearn.neighbors.KNeighborsClassifier`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `scipy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions & Classes\n",
    "- `normalization_subjects()` to normalize data on subject level (`zscore()` from `scipy` is used)\n",
    "- `C_index()` calculate c-index of two given sequences\n",
    "- `Lso_CV()`Class: critical parts to implements leave subject out cv\n",
    "    - `split_data()` method: split data set on subject level\n",
    "    - `KNN_predict()` method: use `sklearn`'s KNN classifier to calculate predictions and performance for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_data=pd.read_csv(\"/Users/mayue/Desktop/TKO-2096/Exe/paindata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_subjects(dataset,column_name):\n",
    "    \"\"\"column name is the column which represent the subject name\"\"\"\n",
    "    names=dataset[column_name].unique()\n",
    "    normalized_data=pd.DataFrame(dataset)\n",
    "#     pdb.set_trace()\n",
    "    for i in names:\n",
    "        if_subject=(normalized_data[column_name]==i)\n",
    "#         pdb.set_trace()\n",
    "        normalized_data.loc[if_subject,'feat1':]=zscore(dataset[if_subject].iloc[:,4:])\n",
    "        #do not normalize the targets data\n",
    "    return normalized_data\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_pain_data=normalization_subjects(pain_data,'subject')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used `zscore()` function to normalize data according to their subjects. \n",
    "\n",
    "And it is necessary to make sure that only feature values have been changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"split the data into features and targets\"\"\"\n",
    "X=normalized_pain_data.iloc[:,4:]\n",
    "y=normalized_pain_data.iloc[:,2]\n",
    "additional_variables=normalized_pain_data.iloc[:,[0,1,3]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the performance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_index(pred,true_labels):\n",
    "    \"\"\"pred and true_labels are sequences which have same length\"\"\"\n",
    "    n=0\n",
    "    h_sum=0.0\n",
    "    for i in range(0,len(true_labels)):\n",
    "        t=true_labels[i]\n",
    "        p=pred[i]\n",
    "        for j in range(i+1,len(true_labels)):\n",
    "            nt=true_labels[j]\n",
    "            np=pred[j]\n",
    "            if t!=nt:\n",
    "                n=n+1\n",
    "#                 pdb.set_trace()\n",
    "                if ((p<np)&(t<nt))|((p>np)&(t>nt)):\n",
    "                    h_sum+=1.0\n",
    "                else:\n",
    "                    if p==np:\n",
    "                        h_sum+=0.5\n",
    "    return float(h_sum/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is directly from exerciese II and it works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfication_accuracy(pred,true_labels):\n",
    "    \"\"\"pred and true_labels are sequences which have same length\"\"\"\n",
    "    n_correct=0.0\n",
    "    m=float(len(true_labels))#amount of instance\n",
    "    for i in range(0,len(true_labels)):\n",
    "#         pdb.set_trace()\n",
    "        n_correct+=int(pred[i]==true_labels[i])\n",
    "    return (float(n_correct/m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for convenience I have also built a function to calculate traditional accuracy between predictions and true labels, which will be used in the CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement leave-subject-out cross-validation with KNN (k=37)\n",
    "Because the data amount is a bit large for this case, so I choose use the off-the-shelf sklearn KNN to finish this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lso_CV():\n",
    "    \n",
    "    def load_data(self,attributes,targets,variables):\n",
    "        \"\"\"load the train data before validating\"\"\"\n",
    "        \"\"\"variables should also be received\"\"\"\n",
    "        self.attributes=attributes\n",
    "        self.targets=targets\n",
    "        self.variables=variables\n",
    "        \n",
    "    def split_data(self,subject_name):\n",
    "        \"\"\"subject name is the column name of subject attribute\"\"\"\n",
    "        \"\"\" return the list of bool Expr \"\"\"\n",
    "        names=self.variables[subject_name].unique()\n",
    "        self.n_subjects=len(names)  #how many subjects there are\n",
    "        subject_index={}\n",
    "        \n",
    "        for i in names:\n",
    "            subject_index[i]=self.variables[subject_name]==i#save member indexes of each subject\n",
    "        \n",
    "        self.subjects_index=subject_index\n",
    "        self.subjects_names=names\n",
    "            \n",
    "        \n",
    "        \n",
    "    def KNN_predict(self,parameter_k):\n",
    "        \"\"\"validate for each subject using sklearn\"\"\"\n",
    "        m=self.attributes.shape[0]\n",
    "        all_results=[]\n",
    "        c_indexes={}\n",
    "        accuracies={}\n",
    "        for i in self.subjects_names:\n",
    "            subject_validate_index=self.subjects_index[i]#get the bool Expr of needed subject\n",
    "            #==============#\n",
    "            #delete subject instances from the training set\n",
    "            X_train=self.attributes[-subject_validate_index]\n",
    "            y_train=self.targets[-subject_validate_index]\n",
    "            #==============#\n",
    "            #add instances from one subject into validate set\n",
    "            X_validate=self.attributes[subject_validate_index]\n",
    "            y_validate=self.targets[subject_validate_index]\n",
    "            #==============#\n",
    "            knn=KNeighborsClassifier(n_neighbors=parameter_k)\n",
    "            knn.fit(X_train,y_train)\n",
    "            pred=knn.predict(X_validate)\n",
    "            #==============#\n",
    "            #save all the predicted results\n",
    "            all_results+=list(pred)\n",
    "            #==============#\n",
    "            #calculate c-index for each subject and save performance into a dict\n",
    "            c_index=C_index(pred,y_validate.values)\n",
    "            c_indexes[i]=c_index\n",
    "            \n",
    "        self.all_results=all_results\n",
    "        self.c_indexes=c_indexes#performance for each subject\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it will be better to package splitting data into folds as a single method. When running KNN I can directly get the indexes of the fold I need.\n",
    "\n",
    "The results attribute records all the predictions over the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Lso_CV()\n",
    "a.load_data(X,y,additional_variables)\n",
    "a.split_data(\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.KNN_predict(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.7641179502282432,\n",
       " 2: 0.5724070992789795,\n",
       " 3: 0.5190438268892794,\n",
       " 4: 0.6868397887323944,\n",
       " 5: 0.6005850585058505,\n",
       " 6: 0.4787750529067596,\n",
       " 7: 0.6641137295081967,\n",
       " 8: 0.6700568707842878,\n",
       " 9: 0.5348868534482759,\n",
       " 10: 0.5807945900253593,\n",
       " 11: 0.6584419373662711,\n",
       " 12: 0.6382644057392772,\n",
       " 13: 0.6561140485911251,\n",
       " 14: 0.5606199514346598,\n",
       " 15: 0.7877790081007052,\n",
       " 16: 0.6848321803740712,\n",
       " 17: 0.6970981507823613,\n",
       " 18: 0.7106073943661971,\n",
       " 19: 0.6498157002649771,\n",
       " 20: 0.5121860207258305,\n",
       " 21: 0.6614544600571451,\n",
       " 22: 0.5180185836263185,\n",
       " 23: 0.6636151452282157,\n",
       " 24: 0.5044012282497441,\n",
       " 25: 0.6062697009302683,\n",
       " 26: 0.5686545898636272,\n",
       " 27: 0.686991419872682,\n",
       " 28: 0.8156826256132634,\n",
       " 29: 0.6325650394219939,\n",
       " 30: 0.646957671957672,\n",
       " 31: 0.5571999031945789}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.c_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance for each subject:\n",
    "```\n",
    " 1: 0.9023891915770873,\n",
    " 2: 0.6682750970604548,\n",
    " 3: 0.5801296133567663,\n",
    " 4: 0.7555017605633803,\n",
    " 5: 0.7563456345634564,\n",
    " 6: 0.5020540271380555,\n",
    " 7: 0.6878073770491804,\n",
    " 8: 0.7649649517259621,\n",
    " 9: 0.6223060344827587,\n",
    " 10: 0.572916314454776,\n",
    " 11: 0.7903131686442326,\n",
    " 12: 0.7448783856364612,\n",
    " 13: 0.7362793655043169,\n",
    " 14: 0.6505277764012092,\n",
    " 15: 0.8331487848942246,\n",
    " 16: 0.776658980271586,\n",
    " 17: 0.7843243243243243,\n",
    " 18: 0.7711267605633803,\n",
    " 19: 0.6704661525024795,\n",
    " 20: 0.5432854279500192,\n",
    " 21: 0.7319334090049187,\n",
    " 22: 0.549761426418885,\n",
    " 23: 0.7818724066390041,\n",
    " 24: 0.5139201637666325,\n",
    " 25: 0.5915372491735219,\n",
    " 26: 0.6320781599837166,\n",
    " 27: 0.8282313866592859,\n",
    " 28: 0.8993402131619015,\n",
    " 29: 0.6551056289662371,\n",
    " 30: 0.7121031746031746,\n",
    " 31: 0.597241045498548\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max': 0.8156826256132634,\n",
       " 'mean': 0.6286835479376972,\n",
       " 'min': 0.4787750529067596,\n",
       " 'range of c-index': 0.33690757270650384}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results={}\n",
    "results['mean']=np.mean(a.c_indexes.values())\n",
    "results['max']=np.max(a.c_indexes.values())\n",
    "results['min']=np.min(a.c_indexes.values())\n",
    "results['range of c-index']=(np.max(a.c_indexes.values())-np.min(a.c_indexes.values()))\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`.c_indexes` attributes records the performance for each fold. \n",
    "\n",
    "|mean c-index|maximum c-index|minmum c-index|range|\n",
    "|:---|---|---|---:|\n",
    "|0.6286835479376972|0.8156826256132634|0.4787750529067596|0.33690757270650384|\n",
    "\n",
    "\n",
    "I have found the performance is not so good as the average c-index is just 0.62 (close to 0.5), which means it doesn't capture much useful information(but basically can predict something). The maximum c-index is 0.82. At least, this is a good score. The range of c-index is about 0.33, which may suggest that the the performance of the model differ on different subjects.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccc",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
